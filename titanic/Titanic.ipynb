{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1M31co5zYev1EFc3D797M0KUzErqLa1RU",
      "authorship_tag": "ABX9TyNJTNbp2YQFRL0ESH0tUzJZ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLHKxE3kPD9h"
      },
      "source": [
        "### Module import, Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeRuNjqQMrK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bad3cb97-034e-4c6d-f376-b609fac2b2f8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p54CTxOTKX0",
        "outputId": "8a6993f7-cd67-4200-ba72-959723176089"
      },
      "source": [
        "cd '/content/drive/MyDrive/Colab Notebooks'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyPeJ1NlTU9q"
      },
      "source": [
        "train = pd.read_csv('./titanic/train.csv')\n",
        "test = pd.read_csv('./titanic/test.csv')\n",
        "\n",
        "train_x = train.drop(['Survived'], axis=1)\n",
        "train_y = train['Survived']\n",
        "\n",
        "test_x = test.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgRtwS9HQ1vn"
      },
      "source": [
        "### Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHfG51utP_o7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d815624-9002-49cd-efcd-97d1f9bb9a98"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "rmCols= ['PassengerId','Name', 'Ticket', 'Cabin']\n",
        "\n",
        "train_x = train_x.drop(rmCols, axis=1)\n",
        "test_x = test_x.drop(rmCols, axis=1)\n",
        "\n",
        "for c in ['Sex', 'Embarked']:\n",
        "  le = LabelEncoder()\n",
        "  le.fit(train[c].fillna('NA'))\n",
        "\n",
        "  train_x[c] = le.transform(train_x[c].fillna('NA'))\n",
        "  test_x[c] = le.transform(test_x[c].fillna('NA'))\n",
        "\n",
        "print(train_x.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 7 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   Pclass    891 non-null    int64  \n",
            " 1   Sex       891 non-null    int64  \n",
            " 2   Age       714 non-null    float64\n",
            " 3   SibSp     891 non-null    int64  \n",
            " 4   Parch     891 non-null    int64  \n",
            " 5   Fare      891 non-null    float64\n",
            " 6   Embarked  891 non-null    int64  \n",
            "dtypes: float64(2), int64(5)\n",
            "memory usage: 48.9 KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avmrXwEGWJjW"
      },
      "source": [
        "### Modeling  \n",
        "\n",
        "TODO \n",
        "\n",
        "---\n",
        "* XGBClassifier\n",
        "  * 개념/동작방식\n",
        "  * params n_estimator, random_state의 개념\n",
        "\n",
        "* visualize\n",
        "  * https://subinium.github.io/MLwithPython-2-4/\n",
        "  * [TF 블로그](https://tensorflow.blog/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/2-4-%EB%B6%84%EB%A5%98-%EC%98%88%EC%B8%A1%EC%9D%98-%EB%B6%88%ED%99%95%EC%8B%A4%EC%84%B1-%EC%B6%94%EC%A0%95/) 참고해서 시각화하기\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaBmbQuGWIo-"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "model = XGBClassifier(n_estimators = 20, random_state=71, use_label_encoder = False)\n",
        "model.fit(train_x,train_y) \n",
        "\n",
        "pred = model.predict_proba(test_x)[:,1]\n",
        "pred_label  = np.where(pred > 0.5, 1, 0)\n",
        "\n",
        "submission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': pred_label})\n",
        "submission.to_csv('./titanic/submission_first.csv', index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-tOlJgAbbcM"
      },
      "source": [
        "### 모델 검증\n",
        "\n",
        "Todo \n",
        "\n",
        "--- \n",
        "* pyplot 이용해 검증결과 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rmYNXUaWiYG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "276f7acd-7c74-4352-aee2-ae4eeb0d5e6c"
      },
      "source": [
        "from sklearn.metrics import log_loss, accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "scores_accuracy = []\n",
        "scores_logloss = []\n",
        "\n",
        "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
        "for tr_idx, va_idx in kf.split(train_x):\n",
        "\n",
        "  tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
        "  tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
        "\n",
        "  model = XGBClassifier(n_estimators = 20, random_state=71, use_label_encoder =False)\n",
        "  model.fit(tr_x,tr_y)\n",
        "\n",
        "  va_pred = model.predict_proba(va_x)[:,1]\n",
        "  logloss= log_loss(va_y, va_pred)\n",
        "  accuracy = accuracy_score(va_y, va_pred > 0.5)\n",
        "\n",
        "  print(f'logloss: {logloss:.4f}, accuracy: {accuracy:.4f}')\n",
        "  scores_logloss.append(logloss)\n",
        "  scores_accuracy.append(accuracy)\n",
        "\n",
        "logloss = np.mean(scores_logloss)\n",
        "accuracy = np.mean(scores_accuracy)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logloss: 0.3972, accuracy: 0.8341\n",
            "logloss: 0.4337, accuracy: 0.8072\n",
            "logloss: 0.4485, accuracy: 0.8027\n",
            "logloss: 0.4285, accuracy: 0.8153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdS59oOQnfBo"
      },
      "source": [
        "\n",
        "### Model tuning\n",
        "\n",
        "Research\n",
        "\n",
        "---\n",
        "* max_depth, min_child_weight의 역할 조사\n",
        "* max_depth: 결정 트리에서 최대 깊이\n",
        "* over,underfitting을 방지하기 위한 변수\n",
        "\n",
        "** hyper parameter 튜닝에 대한 아주 좋은 설명!! 꼭 읽어보기\n",
        "https://statkclee.github.io/model/model-python-xgboost-hyper.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31gwwXE-bc1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "073a17b2-3c64-46f3-b8d8-0e2e4d01d8c3"
      },
      "source": [
        "import itertools\n",
        "\n",
        "param_space = {\n",
        "    'max_depth': [3,5,7],\n",
        "    'min_child_weight': [1.0, 2.0, 4.0]\n",
        "}\n",
        "\n",
        "param_combinations = itertools.product(param_space['max_depth'], param_space['min_child_weight'])\n",
        "\n",
        "params = []\n",
        "scores = []\n",
        "\n",
        "for max_depth, min_child_weight in param_combinations:\n",
        "\n",
        "  score_folds = []\n",
        "  kf = KFold(n_splits= 4, shuffle=True, random_state=71)\n",
        "  for tr_idx, va_idx in kf.split(train_x): \n",
        "    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
        "    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
        "\n",
        "    model = XGBClassifier(n_estimators=20, random_state=71, use_label_encoder=False, max_depth=max_depth, min_child_weight=min_child_weight)\n",
        "    model.fit(tr_x, tr_y)\n",
        "\n",
        "    va_pred = model.predict_proba(va_x)[:,1]\n",
        "    logloss = log_loss(va_y, va_pred)\n",
        "    score_folds.append(logloss)\n",
        "  \n",
        "  score_mean = np.mean(score_folds)\n",
        "\n",
        "  params.append((max_depth, min_child_weight))\n",
        "  scores.append(score_mean)\n",
        "\n",
        "best_idx = np.argsort(scores)[0]\n",
        "best_param = params[best_idx]\n",
        "\n",
        "print(f'max_depth: {best_param[0]}, min_child_weight:{best_param[1]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_depth: 5, min_child_weight:2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs4yfqCzYI0r"
      },
      "source": [
        "### 로지스틱 회귀용 특징 작성\n",
        "\n",
        "Todo \n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJbgtdUrbbQQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f60fb62-502b-47a7-fa98-14bd30e47b4f"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "train_x2 = train.drop(['Survived'], axis=1)\n",
        "test_x2 = test.copy()\n",
        "\n",
        "train_x2 = train_x2.drop(['PassengerId'], axis=1)\n",
        "test_x2 = test_x2.drop(['PassengerId'], axis=1)\n",
        "\n",
        "train_x2 = train_x2.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
        "test_x2 = test_x2.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
        "\n",
        "cat_cols = ['Sex', 'Embarked', 'Pclass']\n",
        "ohe = OneHotEncoder(categories = 'auto', sparse=False)\n",
        "ohe.fit(train_x2[cat_cols].fillna('NA'))\n",
        "\n",
        "ohe_columns = []\n",
        "for i,c in enumerate(cat_cols):\n",
        "  ohe_columns += [f'{c}_{v}' for v in ohe.categories_[i]]\n",
        "\n",
        "ohe_train_x2 = pd.DataFrame(ohe.transform(train_x2[cat_cols].fillna('NA')), columns=ohe_columns)\n",
        "ohe_test_x2 = pd.DataFrame(ohe.transform(test_x2[cat_cols].fillna('NA')), columns = ohe_columns)\n",
        "\n",
        "train_x2 = pd.concat([ train_x2.drop(cat_cols, axis=1), ohe_train_x2], axis=1)\n",
        "test_x2 = pd.concat( [test_x2.drop(cat_cols, axis=1), ohe_test_x2], axis=1)\n",
        "\n",
        "num_cols = ['Age', 'SibSp', 'Parch', 'Fare']\n",
        "for col in num_cols:\n",
        "  train_x2[col].fillna(train_x2[col].mean(), inplace=True)\n",
        "  test_x2[col].fillna(train_x2[col].mean(), inplace=True)\n",
        "\n",
        "train_x2['Fare'] = np.log1p(train_x2['Fare'])\n",
        "test_x2['Fare'] = np.log1p(test_x2['Fare'])\n",
        "\n",
        "print(train_x2.head(10))\n",
        "print(test_x2.head(10))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         Age  SibSp  Parch      Fare  ...  Embarked_S  Pclass_1  Pclass_2  Pclass_3\n",
            "0  22.000000      1      0  2.110213  ...         1.0       0.0       0.0       1.0\n",
            "1  38.000000      1      0  4.280593  ...         0.0       1.0       0.0       0.0\n",
            "2  26.000000      0      0  2.188856  ...         1.0       0.0       0.0       1.0\n",
            "3  35.000000      1      0  3.990834  ...         1.0       1.0       0.0       0.0\n",
            "4  35.000000      0      0  2.202765  ...         1.0       0.0       0.0       1.0\n",
            "5  29.699118      0      0  2.246893  ...         0.0       0.0       0.0       1.0\n",
            "6  54.000000      0      0  3.967694  ...         1.0       1.0       0.0       0.0\n",
            "7   2.000000      3      1  3.094446  ...         1.0       0.0       0.0       1.0\n",
            "8  27.000000      0      2  2.495954  ...         1.0       0.0       0.0       1.0\n",
            "9  14.000000      1      0  3.436268  ...         0.0       0.0       1.0       0.0\n",
            "\n",
            "[10 rows x 13 columns]\n",
            "    Age  SibSp  Parch      Fare  ...  Embarked_S  Pclass_1  Pclass_2  Pclass_3\n",
            "0  34.5      0      0  2.178064  ...         0.0       0.0       0.0       1.0\n",
            "1  47.0      1      0  2.079442  ...         1.0       0.0       0.0       1.0\n",
            "2  62.0      0      0  2.369075  ...         0.0       0.0       1.0       0.0\n",
            "3  27.0      0      0  2.268252  ...         1.0       0.0       0.0       1.0\n",
            "4  22.0      1      1  2.586824  ...         1.0       0.0       0.0       1.0\n",
            "5  14.0      0      0  2.324836  ...         1.0       0.0       0.0       1.0\n",
            "6  30.0      0      0  2.155152  ...         0.0       0.0       0.0       1.0\n",
            "7  26.0      1      1  3.401197  ...         1.0       0.0       1.0       0.0\n",
            "8  18.0      0      0  2.107689  ...         0.0       0.0       0.0       1.0\n",
            "9  21.0      2      0  3.224858  ...         1.0       0.0       0.0       1.0\n",
            "\n",
            "[10 rows x 13 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff8dnDI-iKoy"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model_xgb = XGBClassifier(n_estimators=20, random_state=71, use_label_encoder=False)\n",
        "model_xgb.fit(train_x, train_y)\n",
        "pred_xgb = model_xgb.predict_proba(test_x)[:,1]\n",
        "\n",
        "model_lr = LogisticRegression(solver='lbfgs', max_iter=300)\n",
        "model_lr.fit(train_x2, train_y) \n",
        "pred_lr = model_lr.predict_proba(test_x2)[:,1]\n",
        "\n",
        "pred = pred_xgb * 0.8 + pred_lr * 0.2\n",
        "pred_label = np.where(pred > 0.5, 1, 0)\n",
        "\n",
        "submission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': pred_label})\n",
        "submission.to_csv('submission_first_ensemble.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}